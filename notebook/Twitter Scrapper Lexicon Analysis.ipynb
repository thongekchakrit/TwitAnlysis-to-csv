{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TwitAnlysis-to-csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated Twitter Keyword Sentiment Analysis using Textblob Lexicon\n",
    "By Chakrit Thong Ek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to use file**<br>\n",
    "1) Import the libraries<br>\n",
    "2) Change twitter authentication keys to your own<br>\n",
    "3) Execute cell<br>\n",
    "4) Enter key word (any length) <br>\n",
    "5) Scrapped results are generated and exported to CSV format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import time\n",
    "import warnings\n",
    "from datetime import date\n",
    "from pylab import rcParams\n",
    "from tweepy import *\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Twitter Keyword & Hashtag Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "# Setting up Twitter Scrapper \n",
    "################################################################\n",
    "\n",
    "#### Twitter Authentication Keys\n",
    "class twitter_API_credentials():\n",
    "    CONSUMER_KEY = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "    CONSUMER_SECRET = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "    ACCESS_TOKEN = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "    ACCESS_TOKEN_SECRET = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "    # Key in your twitter credentials\n",
    "    \n",
    "#### Twitter Authenticator\n",
    "class twitter_authenticator():\n",
    "    \n",
    "    def authenticator(self):\n",
    "        auth = OAuthHandler(twitter_API_credentials.CONSUMER_KEY, twitter_API_credentials.CONSUMER_SECRET)\n",
    "        auth.set_access_token(twitter_API_credentials.ACCESS_TOKEN, twitter_API_credentials.ACCESS_TOKEN_SECRET)\n",
    "        api = API(auth)\n",
    "        return api\n",
    "    \n",
    "#### Twitter Cleaner and Processor\n",
    "class twitter_cleaner():\n",
    "    \n",
    "    # Filters the sentences for words before sentiment analysis\n",
    "    def clean_tweet(self, tweet):\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(https?://[^\\s]+)\", \" \", tweet).split())  \n",
    "    \n",
    "    # Perform sentiment analysis and display result\n",
    "    def analyze_sentiment(self, tweet):\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        \n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'POSITIVE'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'NEUTRAL'\n",
    "        else:\n",
    "            return 'NEGATIVE'\n",
    "\n",
    "    def tweets_to_data_frame(self, tweets):\n",
    "        tweets_df = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])        \n",
    "        tweets_df['ID'] = np.array([tweet.id for tweet in tweets])\n",
    "        tweets_df['Length'] = np.array([len(tweet.text) for tweet in tweets])\n",
    "        tweets_df['Date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "        tweets_df['Upload by'] = np.array([tweet.source for tweet in tweets])\n",
    "        tweets_df['Likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "        tweets_df['Retweets'] = np.array([tweet.retweet_count for tweet in tweets])\n",
    "        \n",
    "        # Remove retweet label, @, # and links <- Remove this line to include retweeter ID\n",
    "        # COMMENT THE CODE BELOW TO GENERATE RAW TWEETS FOR CSV OUTPUT\n",
    "        tweets_df['Tweets'].replace('(RT @[A-Za-z0-9_:]+)|(@[A-Za-z0-9_]+)|(#)|(https?://[^\\s]+)', '',\n",
    "                                    #regex=True, inplace=True)\n",
    "        return tweets_df \n",
    "    \n",
    "    def tweets_post_process(tweets):\n",
    "        counter = len(tweets)\n",
    "        tweet_dataframe = clean_twitter.tweets_to_data_frame(tweets)\n",
    "        tweet_dataframe['Sentiment'] = np.array([clean_twitter.analyze_sentiment(tweet) for tweet in tweet_dataframe['Tweets']])\n",
    "        tweet_dataframe.drop_duplicates(subset='Tweets', inplace=True)\n",
    "        tweet_dataframe.reset_index(inplace=True, drop=True)\n",
    "        return(tweet_dataframe)\n",
    "        \n",
    "#### Twitter Scrapper\n",
    "class twitter_scrapper():\n",
    "    \n",
    "    def scrapper(search_hashtag):\n",
    "        try:\n",
    "            fetch_tweet = api.search(search_hashtag, count=100, lang='en')\n",
    "            return fetch_tweet\n",
    "            time.sleep(timer.limitter())\n",
    "            print('Limit reached, please wait')\n",
    "        except:\n",
    "            print('Sorry there was an error ')\n",
    "            return None\n",
    "\n",
    "#########################################################\n",
    "# Plotting a bar graph with result\n",
    "#########################################################\n",
    "\n",
    "class plotting_barg():\n",
    "    \n",
    "    def bar_graph(output_tweet):\n",
    "        #initialize the plotly figure\n",
    "        count_sentiment = pd.DataFrame((output_tweet['Sentiment'].value_counts()))\n",
    "\n",
    "        colors = ['lightslategray',] * 3\n",
    "        colors[0] = '#1f77b4'\n",
    "\n",
    "        fig = go.Figure(data=[go.Bar(x=count_sentiment.index, y=count_sentiment.Sentiment, marker_color=colors)])\n",
    "        fig.update_layout(title={'text': ('Figure 2. SENTIMENT COUNT: ' + search_hashtag.upper()),\n",
    "                               'y':0.9, 'x':0.5, 'xanchor': 'center','yanchor': 'top'},font=dict(family='Arial',size=18),\n",
    "                              template='simple_white', yaxis=dict( title='COUNT', title_font_family=\"Arial\", \n",
    "                                                                      titlefont_size=16, tickfont_size=16))\n",
    "        \n",
    "        fig.show()\n",
    "    \n",
    "    def percentage_horizontal(output_tweet):\n",
    "        # Data restructuring, get count of sentiments\n",
    "        Percentage = pd.DataFrame((output_tweet['Sentiment'].value_counts('POSITIVE')*100).round(2))\n",
    "        Percentage['Sentiment'] = Percentage['Sentiment'].astype(int)\n",
    "        \n",
    "        # Plotting horizontal Plotly Bar graph\n",
    "        top_labels = Percentage.index\n",
    "\n",
    "        colors = ['rgba(38, 24, 74, 0.8)', 'rgba(71, 58, 131, 0.8)',\n",
    "                  'rgba(122, 120, 168, 0.8)']\n",
    "\n",
    "        x_data = [Percentage['Sentiment'].tolist()]\n",
    "        y_data= ['SENTIMENT']\n",
    "        fig = go.Figure()\n",
    "\n",
    "        for i in range(0, len(x_data[0])):\n",
    "            for xd, yd in zip(x_data, y_data):\n",
    "                fig.add_trace(go.Bar(\n",
    "                    x=[xd[i]], y=[yd],\n",
    "                    orientation='h',\n",
    "                    marker=dict(\n",
    "                        color=colors[i],\n",
    "                        line=dict(color='rgb(248, 248, 249)', width=1)\n",
    "                    )\n",
    "                ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            xaxis=dict(\n",
    "                showgrid=False,\n",
    "                showline=False,\n",
    "                showticklabels=False,\n",
    "                zeroline=False,\n",
    "                domain=[0.15, 1]\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                showgrid=False,\n",
    "                showline=False,\n",
    "                showticklabels=False,\n",
    "                zeroline=False,\n",
    "            ),\n",
    "            barmode='stack',\n",
    "            paper_bgcolor='rgb(255, 255, 255)',\n",
    "            plot_bgcolor='rgb(255, 255, 255)',\n",
    "            margin=dict(l=120, r=10, t=140, b=80),\n",
    "            showlegend=False,\n",
    "        )\n",
    "\n",
    "        annotations = []\n",
    "\n",
    "        for yd, xd in zip(y_data, x_data):\n",
    "            # labeling the y-axis\n",
    "            annotations.append(dict(xref='paper', yref='y',\n",
    "                                    x=0.14, y=yd,\n",
    "                                    xanchor='right',\n",
    "                                    text=str(yd),\n",
    "                                    font=dict(family='Arial', size=16,\n",
    "                                              color='rgb(67, 67, 67)'),\n",
    "                                    showarrow=False, align='right'))\n",
    "            # labeling the first percentage of each bar (x_axis)\n",
    "            annotations.append(dict(xref='x', yref='y',\n",
    "                                    x=xd[0] / 2, y=yd,\n",
    "                                    text=str(xd[0]) + '%',\n",
    "                                    font=dict(family='Arial', size=16,\n",
    "                                              color='rgb(248, 248, 255)'),\n",
    "                                    showarrow=False))\n",
    "            # labeling the first Likert scale (on the top)\n",
    "            if yd == y_data[-1]:\n",
    "                annotations.append(dict(xref='x', yref='paper',\n",
    "                                        x=xd[0] / 2, y=1.1,\n",
    "                                        text=top_labels[0],\n",
    "                                        font=dict(family='Arial', size=16,\n",
    "                                                  color='rgb(67, 67, 67)'),\n",
    "                                        showarrow=False))\n",
    "            space = xd[0]\n",
    "            for i in range(1, len(xd)):\n",
    "                    # labeling the rest of percentages for each bar (x_axis)\n",
    "                    annotations.append(dict(xref='x', yref='y',\n",
    "                                            x=space + (xd[i]/2), y=yd,\n",
    "                                            text=str(xd[i]) + '%',\n",
    "                                            font=dict(family='Arial', size=16,\n",
    "                                                      color='rgb(248, 248, 255)'),\n",
    "                                            showarrow=False))\n",
    "                    # labeling the Likert scale\n",
    "                    if yd == y_data[-1]:\n",
    "                        annotations.append(dict(xref='x', yref='paper',\n",
    "                                                x=space + (xd[i]/2), y=1.1,\n",
    "                                                text=top_labels[i],\n",
    "                                                font=dict(family='Arial', size=16,\n",
    "                                                          color='rgb(67, 67, 67)'),\n",
    "                                                showarrow=False))\n",
    "                    space += xd[i]\n",
    "                    \n",
    "        fig.update_layout(title={ 'text': ('Figure 1. SENTIMENT (%) ON SEARCH TERM: ' + search_hashtag.upper()),\n",
    "                               'y':0.9, 'x':0.5, 'xanchor': 'center','yanchor': 'top'}, \n",
    "                                font=dict(family='Arial',size=18),annotations=annotations)\n",
    "\n",
    "        fig.show()\n",
    "    \n",
    "#################################################################\n",
    "#################################################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Initialize class twitter cleaner\n",
    "    clean_twitter = twitter_cleaner()\n",
    "    \n",
    "    # Request for keyword\n",
    "    search_hashtag = input('Please insert Keyword? (i.e #GE2020): ')\n",
    "    # Authenticate program\n",
    "    api = twitter_authenticator().authenticator()\n",
    "    \n",
    "    # Scrape and process tweets into dataframe\n",
    "    tweets = twitter_scrapper.scrapper(search_hashtag)\n",
    "    output_tweet = twitter_cleaner.tweets_post_process(tweets)\n",
    "    print('We have fetched '+ str(len(output_tweet)) + ' tweets!')\n",
    "    print('File has been saved to local drive')\n",
    "    \n",
    "    # Plotting graphs\n",
    "    plotting_barg.percentage_horizontal(output_tweet)\n",
    "    plotting_barg.bar_graph(output_tweet)\n",
    "    \n",
    "    # Extract dataframe to csv file\n",
    "    output_tweet.to_csv('Twitter_Analysis.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
